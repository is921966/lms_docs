# AI Interaction and Security Rules for LMS Project

## AI Usage Guidelines

### When to Use AI Assistance
AI should be used for:
- **Code generation** - Boilerplate, repetitive patterns
- **Problem solving** - Algorithm suggestions, optimization
- **Documentation** - API docs, code comments
- **Code review** - Finding bugs, suggesting improvements
- **Learning** - Understanding new concepts, best practices
- **Refactoring** - Improving code structure
- **Testing** - Generating test cases

### When NOT to Use AI
AI should NOT be used for:
- **Security-critical code** - Authentication, encryption
- **Business logic** - Core algorithms unique to your business
- **Sensitive data handling** - PII, financial data processing
- **Legal/Compliance code** - Without human verification
- **Production credentials** - Never share real secrets

## Data Security and Privacy

### Information to NEVER Share with AI
```swift
// ❌ NEVER share these with AI:

// 1. Real API keys
let apiKey = "sk-proj-real-api-key-xxxxx" // ❌ NEVER

// 2. Production URLs
let baseURL = "https://api.production.company.com" // ❌ NEVER

// 3. Real user data
let userData = [
    "email": "john.doe@realcompany.com", // ❌ NEVER
    "ssn": "123-45-6789" // ❌ NEVER
]

// 4. Database credentials
let dbConnection = "postgresql://prod_user:real_pass@prod.db.com" // ❌ NEVER

// 5. Private keys or certificates
let privateKey = "-----BEGIN RSA PRIVATE KEY-----..." // ❌ NEVER

// 6. Internal documentation
let internalDocs = "Company confidential process..." // ❌ NEVER
```

### Safe Alternatives
```swift
// ✅ Use these instead:

// 1. Mock API keys
let apiKey = "mock-api-key-for-testing" // ✅ SAFE

// 2. Local/mock URLs
let baseURL = "https://api.example.com" // ✅ SAFE

// 3. Fake user data
let userData = [
    "email": "test@example.com", // ✅ SAFE
    "ssn": "000-00-0000" // ✅ SAFE
]

// 4. Generic connection strings
let dbConnection = "postgresql://user:pass@localhost/testdb" // ✅ SAFE

// 5. Placeholder keys
let privateKey = "mock-private-key-placeholder" // ✅ SAFE

// 6. Generic documentation
let publicDocs = "Standard REST API implementation" // ✅ SAFE
```

## Code Anonymization Techniques

### Before Sharing Code
```swift
// Original (with sensitive data)
class UserService {
    private let apiEndpoint = "https://api.tsumuniversity.ru/v2"
    private let apiKey = "TSM-2024-PROD-KEY-X9Y8Z7"
    
    func authenticateUser(email: String, password: String) {
        // Company-specific authentication logic
        let hash = TsumCustomHasher.hash(password, salt: "tsm2024")
        // ...
    }
}

// Anonymized (safe to share)
class UserService {
    private let apiEndpoint = "https://api.example.com/v1"
    private let apiKey = ProcessInfo.processInfo.environment["API_KEY"] ?? ""
    
    func authenticateUser(email: String, password: String) {
        // Standard authentication logic
        let hash = SHA256.hash(data: password.data(using: .utf8)!)
        // ...
    }
}
```

### Data Anonymization Script
```swift
// Utilities/Anonymizer.swift
struct Anonymizer {
    static func anonymizeEmail(_ email: String) -> String {
        let components = email.split(separator: "@")
        guard components.count == 2 else { return "user@example.com" }
        
        let username = String(components[0].prefix(2)) + "***"
        return "\(username)@example.com"
    }
    
    static func anonymizeURL(_ url: String) -> String {
        return url
            .replacingOccurrences(of: #"https?://[^/]+"#, with: "https://api.example.com", options: .regularExpression)
            .replacingOccurrences(of: #"/v\d+"#, with: "/v1", options: .regularExpression)
    }
    
    static func anonymizeAPIKey(_ key: String) -> String {
        return "mock-api-key-\(key.count)-chars"
    }
}
```

## Prompt Engineering Best Practices

### Effective Prompts
```markdown
# GOOD Prompt Example
"Create a Swift function that validates email format using regex. 
Requirements:
- Should return Bool
- Handle edge cases (empty string, special characters)
- Include unit tests
- Follow Swift naming conventions
- Add documentation comments"

# BAD Prompt Example
"Make email validation" // Too vague
```

### Context Providing
```markdown
# Providing Context
"I'm building an iOS app using SwiftUI and Clean Architecture.
Current structure:
- Domain layer with entities
- Application layer with use cases
- Presentation layer with MVVM
- Using Combine for reactive programming

Task: Create a login view model that:
1. Validates input
2. Calls authentication use case
3. Handles loading states
4. Provides error messages"
```

## AI Code Review Process

### Structured Review Request
```markdown
# Code Review Request Template

## Code to Review:
```swift
[paste your code here]
```

## Review Focus:
- [ ] Architecture compliance
- [ ] Performance optimization
- [ ] Security vulnerabilities
- [ ] Error handling
- [ ] Test coverage

## Context:
- Framework: SwiftUI
- Architecture: Clean Architecture
- Testing: XCTest with Quick/Nimble

## Specific Questions:
1. Is the error handling comprehensive?
2. Are there any memory leaks?
3. Does this follow SOLID principles?
```

## Security Validation Process

### AI-Generated Code Validation
```swift
// Security/AICodeValidator.swift
struct AICodeValidator {
    enum ValidationError: Error {
        case hardcodedCredentials
        case insecureNetworking
        case sqlInjectionRisk
        case insufficientValidation
        case memoryLeak
    }
    
    static func validate(_ code: String) throws {
        // Check for hardcoded credentials
        let credentialPatterns = [
            #"api[_-]?key\s*=\s*"[^"]*""#,
            #"password\s*=\s*"[^"]*""#,
            #"secret\s*=\s*"[^"]*""#,
            #"token\s*=\s*"[^"]*""#
        ]
        
        for pattern in credentialPatterns {
            if code.range(of: pattern, options: .regularExpression) != nil {
                throw ValidationError.hardcodedCredentials
            }
        }
        
        // Check for HTTP usage
        if code.contains("http://") && !code.contains("localhost") {
            throw ValidationError.insecureNetworking
        }
        
        // Check for SQL injection risks
        if code.contains("SELECT * FROM") && code.contains("\\(") {
            throw ValidationError.sqlInjectionRisk
        }
        
        // Check for force unwrapping
        if code.contains("!") && !code.contains("!= ") {
            print("Warning: Force unwrapping detected")
        }
    }
}
```

## AI Tool Configuration

### Cursor Settings
```json
{
  "ai.model": "gpt-4",
  "ai.temperature": 0.3,
  "ai.maxTokens": 2000,
  "ai.includeContext": true,
  "ai.anonymizeData": true,
  "ai.securityCheck": true,
  "ai.codeReview": {
    "enabled": true,
    "autoSuggest": false,
    "includeTests": true
  }
}
```

### Pre-commit Hook for AI Code
```bash
#!/bin/bash
# .git/hooks/pre-commit-ai

# Check for potential AI-generated code markers
if git diff --cached --name-only | xargs grep -l "AI-generated\|Generated by\|Copilot" > /dev/null; then
    echo "⚠️  AI-generated code detected. Running security validation..."
    
    # Run security checks
    swift run AICodeValidator
    
    if [ $? -ne 0 ]; then
        echo "❌ Security validation failed. Please review AI-generated code."
        exit 1
    fi
fi
```

## Responsible AI Usage

### Attribution
```swift
// When using AI-generated code, always attribute:

/// LoginViewModel implementation
/// 
/// This code was partially generated with AI assistance and has been:
/// - Reviewed for security vulnerabilities
/// - Tested with comprehensive unit tests
/// - Modified to meet project standards
/// - Validated against architecture guidelines
///
/// Last human review: 2024-03-15
/// Reviewer: John Doe
```

### Continuous Learning
```markdown
# AI Learning Log

## Date: 2024-03-15
### Prompt Used:
"Create a thread-safe cache implementation with LRU eviction"

### AI Response Summary:
- Provided NSCache-based implementation
- Suggested actor-based alternative
- Included thread safety considerations

### Modifications Made:
1. Changed from NSCache to custom implementation
2. Added telemetry for cache hits/misses
3. Implemented configurable eviction policies

### Lessons Learned:
- AI tends to suggest NSCache for all caching needs
- Custom implementations often needed for specific requirements
- Always verify thread safety claims with tests
```

## Emergency Procedures

### If Sensitive Data Was Shared
1. **Immediately** rotate any exposed credentials
2. **Document** what was exposed and when
3. **Notify** security team
4. **Review** logs for any unauthorized access
5. **Update** security training for team

### Incident Report Template
```markdown
# AI Security Incident Report

**Date:** 2024-03-15
**Reporter:** John Doe
**Severity:** High/Medium/Low

## What Happened:
[Description of what sensitive data was shared]

## Root Cause:
[Why the data was shared - lack of awareness, accident, etc.]

## Impact Assessment:
- [ ] Credentials exposed
- [ ] Internal URLs exposed
- [ ] User data exposed
- [ ] Business logic exposed

## Remediation Steps:
1. [Step taken to fix]
2. [Additional security measures]

## Prevention:
[How to prevent this in future]
```

## Best Practices Summary

### DO ✅
- Anonymize all data before sharing
- Use environment variables for secrets
- Review AI-generated code thoroughly
- Test all AI suggestions
- Document AI usage
- Learn from AI interactions
- Share generic patterns, not specifics

### DON'T ❌
- Share production credentials
- Expose internal URLs or IPs
- Share proprietary algorithms
- Trust AI blindly
- Skip security reviews
- Share customer data
- Ignore AI limitations

## AI Integration Testing

### Test AI-Generated Code
```swift
class AIGeneratedCodeTests: XCTestCase {
    func testAIGeneratedFunction() {
        // Always test AI-generated code
        measure {
            // Performance test
        }
        
        // Edge cases
        XCTAssertNoThrow(aiFunction(nil))
        XCTAssertThrows(aiFunction(invalidInput))
        
        // Security
        XCTAssertFalse(containsHardcodedSecrets(aiFunction))
        
        // Memory
        trackForMemoryLeaks(aiFunction)
    }
}
```

Remember: AI is a powerful tool, but it requires responsible usage. Always prioritize security and privacy over convenience. 